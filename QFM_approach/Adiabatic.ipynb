{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef275edf",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a0605",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf2715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Dict, Sequence, Union, Optional, Any\n",
    "from math import comb, gamma, log\n",
    "from scipy.special import digamma\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# mutual information\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "# qiskit\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, Pauli, SparsePauliOp\n",
    "from qiskit.circuit.library import PauliEvolutionGate\n",
    "from qiskit.synthesis import LieTrotter, SuzukiTrotter\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, EstimatorV2 as Estimator\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "\n",
    "# saving and loading\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cebd67",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e09d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trotter_steps = 1\n",
    "delta_t = 0.005\n",
    "T = n_trotter_steps * delta_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10003f",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c734742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(X_train: np.ndarray, X_test: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    scaler = StandardScaler() # Rescale the data using z-score: (x - μ (mean))/μ (standard deviation)\n",
    "    X_tr = scaler.fit_transform(X_train)\n",
    "    Xte = scaler.transform(X_test)\n",
    "    return X_tr, Xte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "145f8ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MATS3v  nHBint10  MATS3s  MATS3p  nHBDon_Lipinski  minHBint8  MATS3e  \\\n",
      "0  0.0908         0  0.0075  0.0173                0        0.0 -0.0436   \n",
      "1  0.0213         0  0.1144 -0.0410                0        0.0  0.1231   \n",
      "2  0.0018         0 -0.0156 -0.0765                2        0.0 -0.1138   \n",
      "3 -0.0251         0 -0.0064 -0.0894                3        0.0 -0.0747   \n",
      "4  0.0135         0  0.0424 -0.0353                0        0.0 -0.0638   \n",
      "\n",
      "   MATS3c  minHBint2  MATS3m  ...   WTPT-4   WTPT-5  ETA_EtaP_L  ETA_EtaP_F  \\\n",
      "0  0.0409        0.0  0.1368  ...   0.0000   0.0000      0.1780      1.5488   \n",
      "1 -0.0316        0.0  0.1318  ...   8.8660  19.3525      0.1739      1.3718   \n",
      "2 -0.1791        0.0  0.0615  ...   5.2267  27.8796      0.1688      1.4395   \n",
      "3 -0.1151        0.0  0.0361  ...   7.7896  24.7336      0.1702      1.4654   \n",
      "4  0.0307        0.0  0.0306  ...  12.3240  19.7486      0.1789      1.4495   \n",
      "\n",
      "   ETA_EtaP_B  nT5Ring  SHdNH  ETA_dEpsilon_C  MDEO-22  Class  \n",
      "0      0.0088        0    0.0         -0.0868     0.00      1  \n",
      "1      0.0048        2    0.0         -0.0810     0.25      1  \n",
      "2      0.0116        2    0.0         -0.1004     0.00      1  \n",
      "3      0.0133        2    0.0         -0.1010     0.00      1  \n",
      "4      0.0120        2    0.0         -0.1071     0.00      1  \n",
      "\n",
      "[5 rows x 1204 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"C:/Users/jiriv/Documents/škola/Diplom_thesis/Quantum-feature-maps/Dataset/data.csv\"\n",
    "df = pd.read_csv(dataset_dir)\n",
    "\n",
    "# Map the class labels to binary values\n",
    "df['Class'] = df['Class'].map({'NonToxic': 1,'Toxic': 0})\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d7f6f",
   "metadata": {},
   "source": [
    "# Quantum algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea649f13",
   "metadata": {},
   "source": [
    "## C_s via mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06094294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mutual_information(a: np.ndarray, b: np.ndarray, random_state: int = 0, n_neighbors: int = 3) -> float:\n",
    "    a = np.asarray(a)\n",
    "    b = np.asarray(b)\n",
    "\n",
    "    # X must be 2D: (n_samples, n_features). For single feature make it (n_samples, 1)\n",
    "    if a.ndim == 1:\n",
    "        X = a.reshape(-1, 1)\n",
    "    elif a.ndim == 2 and a.shape[1] == 1:\n",
    "        X = a\n",
    "    else:\n",
    "        # If user passed a multi-column array, keep as-is (mutual_info_regression will return array)\n",
    "        X = a\n",
    "\n",
    "    # y must be 1D\n",
    "    if b.ndim > 1:\n",
    "        y = b.ravel()\n",
    "    else:\n",
    "        y = b\n",
    "\n",
    "    mi = mutual_info_regression(X, y, random_state=random_state, n_neighbors=n_neighbors)\n",
    "    return float(mi[0]) \n",
    "\n",
    "def mi_matrix(X: np.ndarray, plot_option: bool) -> pd.DataFrame:\n",
    "    n_features = X.shape[1]\n",
    "    #feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "    feature_names = df.columns[:-1]\n",
    "\n",
    "    MI = np.zeros((n_features, n_features))\n",
    "\n",
    "    # Compute pairwise mutual information\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            mi = compute_mutual_information(X[:, i], X[:, j])\n",
    "            MI[i, j] = mi\n",
    "            MI[j, i] = mi\n",
    "\n",
    "    # Put into a pandas DataFrame\n",
    "    MI_df = pd.DataFrame(MI, columns=feature_names, index=feature_names)\n",
    "\n",
    "    if plot_option == True:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(MI_df, interpolation='nearest')\n",
    "        plt.colorbar(label='Mutual Information')\n",
    "        plt.xticks(ticks=np.arange(n_features), labels=feature_names, rotation=45, ha='right')\n",
    "        plt.yticks(ticks=np.arange(n_features), labels=feature_names)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return MI_df\n",
    "\n",
    "PairList = List[Tuple[Tuple[int, int], float]]\n",
    "\n",
    "def compute_all_pairwise_mi(\n",
    "    X: np.ndarray,\n",
    "    feature_names: Optional[List[str]] = None,\n",
    "    random_state: int = 0,\n",
    "    n_neighbors: int = 3,\n",
    "    n_jobs: int = 1,\n",
    "    verbose: bool = False\n",
    ") -> List[Tuple[Tuple[int, int], float]]:\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be 2D (n_samples, n_features)\")\n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "    elif len(feature_names) != n_features:\n",
    "        raise ValueError(\"feature_names length mismatch\")\n",
    "\n",
    "    pairs = list(combinations(range(n_features), 2))\n",
    "    if verbose:\n",
    "        print(f\"Computing {len(pairs)} pairs (n_features={n_features}) using n_jobs={n_jobs} ...\")\n",
    "\n",
    "    def _compute_pair(pair):\n",
    "        i, j = pair\n",
    "        mi_val = compute_mutual_information(\n",
    "            X[:, i], X[:, j],\n",
    "            random_state=random_state,\n",
    "            n_neighbors=n_neighbors\n",
    "        )\n",
    "        return (i, j, float(mi_val))\n",
    "\n",
    "    # parallel computation\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_compute_pair)(pair) for pair in pairs\n",
    "    )\n",
    "\n",
    "    # sort by absolute MI\n",
    "    results_sorted = sorted(results, key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "    # return list of ((i,j), MI)\n",
    "    compact_list = [((i, j), mi) for (i, j, mi) in results_sorted]\n",
    "\n",
    "    return compact_list\n",
    "\n",
    "\n",
    "def select_top_pairs(pairs: Union[pd.DataFrame, PairList],\n",
    "                     top_n: int = 10,\n",
    "                     mode: str = \"absolute\",\n",
    "                     feature_names: Optional[List[str]] = None,\n",
    "                     return_type: str = \"list\"\n",
    "                     ) -> Union[PairList, pd.DataFrame]:\n",
    "    \n",
    "    if mode not in {\"absolute\", \"largest\", \"most_negative\"}:\n",
    "        raise ValueError(\"mode must be 'absolute', 'largest', or 'most_negative'\")\n",
    "\n",
    "    pair_list = list(pairs)\n",
    "\n",
    "    # build enriched list (i,j,mi,abs_mi)\n",
    "    enriched = [ (a_b[0][0], a_b[0][1], float(a_b[1]), abs(float(a_b[1]))) for a_b in pair_list ]\n",
    "\n",
    "    # sort according to mode\n",
    "    if mode == \"absolute\":\n",
    "        enriched_sorted = sorted(enriched, key=lambda t: t[3], reverse=True)\n",
    "    elif mode == \"largest\":\n",
    "        enriched_sorted = sorted(enriched, key=lambda t: t[2], reverse=True)\n",
    "    else:  # most_negative\n",
    "        enriched_sorted = sorted(enriched, key=lambda t: t[2])  # ascending (most negative first)\n",
    "\n",
    "    # selection\n",
    "    chosen = enriched_sorted[:top_n]\n",
    "\n",
    "    # format output\n",
    "    if return_type == \"list\":\n",
    "        out_list: PairList = [(((int(i), int(j))), float(mi)) for (i, j, mi, _) in chosen]\n",
    "        return out_list\n",
    "\n",
    "    # build DataFrame\n",
    "    rows = []\n",
    "    for i, j, mi, abs_mi in chosen:\n",
    "        if feature_names is not None:\n",
    "            name_i = feature_names[int(i)]\n",
    "            name_j = feature_names[int(j)]\n",
    "            names = (name_i, name_j)\n",
    "        else:\n",
    "            names = (f\"Feature_{int(i)}\", f\"Feature_{int(j)}\")\n",
    "        rows.append({\n",
    "            'S_idx': (int(i), int(j)),\n",
    "            'S_names': names,\n",
    "            'mi': float(mi),\n",
    "            'abs_mi': float(abs_mi)\n",
    "        })\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    return df_out\n",
    "\n",
    "# I(x,y,z) = H(x) + H(y) + H(z) - H(x,y) - H(x,z) - H(y,z) + H(x,y,z)\n",
    "\n",
    "def _entropy_knn(X: np.ndarray, k: int = 3) -> float:\n",
    "    \"\"\"\n",
    "    Kozachenko-Leonenko k-NN entropy estimator for continuous variables.\n",
    "    X: shape (n_samples, d)  (if 1D pass reshape(-1,1))\n",
    "    returns entropy (natural units, nats)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    n, d = X.shape\n",
    "    if n <= k:\n",
    "        raise ValueError(f\"n_samples ({n}) must be > k ({k})\")\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X, return_distance=True)\n",
    "    # distance to k-th neighbor (exclude self at distance 0)\n",
    "    eps = distances[:, -1] + 1e-15  # tiny offset for numerical stability\n",
    "\n",
    "    # volume of unit ball in d dimensions (Euclidean)\n",
    "    c_d = (np.pi ** (d / 2.0)) / gamma(d / 2.0 + 1.0)\n",
    "    avg_log_eps = np.mean(np.log(eps))\n",
    "\n",
    "    H = digamma(n) - digamma(k) + d * avg_log_eps + log(c_d)\n",
    "    return float(H)\n",
    "\n",
    "def mi3_knn(x: Union[np.ndarray, list], y: Union[np.ndarray, list], z: Union[np.ndarray, list], k: int = 3, to_bits: bool = False) -> float:\n",
    "\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "    z = np.asarray(z).reshape(-1)\n",
    "\n",
    "    if not (len(x) == len(y) == len(z)):\n",
    "        raise ValueError(\"x, y, z must have the same number of samples\")\n",
    "\n",
    "    Hx  = _entropy_knn(x.reshape(-1, 1), k=k)\n",
    "    Hy  = _entropy_knn(y.reshape(-1, 1), k=k)\n",
    "    Hz  = _entropy_knn(z.reshape(-1, 1), k=k)\n",
    "\n",
    "    Hxy = _entropy_knn(np.column_stack([x, y]), k=k)\n",
    "    Hxz = _entropy_knn(np.column_stack([x, z]), k=k)\n",
    "    Hyz = _entropy_knn(np.column_stack([y, z]), k=k)\n",
    "\n",
    "    Hxyz = _entropy_knn(np.column_stack([x, y, z]), k=k)\n",
    "\n",
    "    I_xyz = (Hx + Hy + Hz) - (Hxy + Hxz + Hyz) + Hxyz\n",
    "\n",
    "    if to_bits:\n",
    "        I_xyz = I_xyz / log(2.0)\n",
    "\n",
    "    return float(I_xyz)\n",
    "\n",
    "TripletList = List[Tuple[Tuple[int,int,int], float]]\n",
    "\n",
    "def compute_all_triplet_mi(\n",
    "    X: np.ndarray,\n",
    "    feature_names: Optional[List[str]] = None,\n",
    "    k: int = 3,\n",
    "    to_bits: bool = False,\n",
    "    n_jobs: int = 1,\n",
    "    verbose: bool = False\n",
    ") -> TripletList:\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(\"X must be 2D (n_samples, n_features)\")\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "    elif len(feature_names) != n_features:\n",
    "        raise ValueError(\"feature_names length mismatch\")\n",
    "\n",
    "    combos = list(combinations(range(n_features), 3))\n",
    "    if verbose:\n",
    "        print(f\"Computing {len(combos)} triplets (n_features={n_features}) with k={k} using n_jobs={n_jobs}...\")\n",
    "\n",
    "    def _compute_for_triplet(trip):\n",
    "        i, j, l = trip\n",
    "        mi_val = mi3_knn(X[:, i], X[:, j], X[:, l], k=k, to_bits=to_bits)\n",
    "        return ((int(i), int(j), int(l)), float(mi_val))\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(_compute_for_triplet)(trip) for trip in combos\n",
    "    )\n",
    "\n",
    "    # sort by absolute MI descending\n",
    "    results_sorted = sorted(results, key=lambda t: abs(t[1]), reverse=True)\n",
    "    return results_sorted\n",
    "\n",
    "\n",
    "def select_top_triplets(\n",
    "    triplets: Union[pd.DataFrame, TripletList],\n",
    "    top_n: int = 10,\n",
    "    mode: str = \"absolute\",\n",
    "    feature_names: Optional[List[str]] = None,\n",
    "    return_type: str = \"list\"\n",
    ") -> Union[TripletList, pd.DataFrame]:\n",
    "\n",
    "    if mode not in {\"absolute\", \"largest\", \"most_negative\"}:\n",
    "        raise ValueError(\"mode must be 'absolute', 'largest', or 'most_negative'\")\n",
    "\n",
    "\n",
    "    trip_list = list(triplets)\n",
    "\n",
    "    # enrich: (i,j,k,mi,abs_mi)\n",
    "    enriched = [ (int(t[0][0]), int(t[0][1]), int(t[0][2]), float(t[1]), abs(float(t[1]))) for t in trip_list ]\n",
    "\n",
    "    # sort according to mode\n",
    "    if mode == \"absolute\":\n",
    "        enriched_sorted = sorted(enriched, key=lambda x: x[4], reverse=True)\n",
    "    elif mode == \"largest\":\n",
    "        enriched_sorted = sorted(enriched, key=lambda x: x[3], reverse=True)\n",
    "    else:  # most_negative\n",
    "        enriched_sorted = sorted(enriched, key=lambda x: x[3])  # ascending (most negative first)\n",
    "\n",
    "    # selection\n",
    "    chosen = enriched_sorted[:top_n]\n",
    "    \n",
    "    # format output\n",
    "    if return_type == \"list\":\n",
    "        out_list: TripletList = [(((int(i), int(j), int(k))), float(mi)) for (i,j,k,mi,_) in chosen]\n",
    "        return out_list\n",
    "\n",
    "    # build DataFrame\n",
    "    rows = []\n",
    "    for i,j,k,mi,abs_mi in chosen:\n",
    "        if feature_names is not None:\n",
    "            names = (feature_names[int(i)], feature_names[int(j)], feature_names[int(k)])\n",
    "        else:\n",
    "            names = (f\"Feature_{int(i)}\", f\"Feature_{int(j)}\", f\"Feature_{int(k)}\")\n",
    "        rows.append({\n",
    "            'S_idx': (int(i), int(j), int(k)),\n",
    "            'S_names': names,\n",
    "            'mi': float(mi),\n",
    "            'abs_mi': float(abs_mi)\n",
    "        })\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    return df_out\n",
    "\n",
    "def create_set(\n",
    "    k: str,\n",
    "    top_pairs: Optional[List[Tuple[Tuple[int, int], float]]] = None,\n",
    "    top_triplets: Optional[List[Tuple[Tuple[int, int, int], float]]] = None\n",
    ") -> List[int]:\n",
    "    set = []\n",
    "\n",
    "    # Use only pairs\n",
    "    if k == '2':\n",
    "        set = top_pairs\n",
    "\n",
    "    # Use only triplets\n",
    "    elif k == '3':\n",
    "        set = top_triplets\n",
    "\n",
    "    # Combine both\n",
    "    elif k == '2+3':\n",
    "        set = []\n",
    "        if top_pairs is not None:\n",
    "            set.extend(top_pairs)\n",
    "        if top_triplets is not None:\n",
    "            set.extend(top_triplets)\n",
    "    return set\n",
    "\n",
    "def divide_into_subsets(\n",
    "    items: List[Any],\n",
    "    num_subsets: Optional[int] = None,\n",
    "    subset_size: Optional[int] = None,\n",
    "    shuffle: bool = True\n",
    ") -> List[List[Any]]:\n",
    "    \n",
    "    if num_subsets is None and subset_size is None:\n",
    "        raise ValueError(\"Provide either num_subsets or subset_size.\")\n",
    "\n",
    "    items_copy = items.copy()\n",
    "    if shuffle:\n",
    "        random.shuffle(items_copy)\n",
    "\n",
    "    if subset_size is not None:\n",
    "        num_subsets = max(1, (len(items_copy) + subset_size - 1) // subset_size)\n",
    "\n",
    "    subsets = []\n",
    "    avg_size = len(items_copy) / num_subsets\n",
    "\n",
    "    start = 0\n",
    "    for i in range(num_subsets):\n",
    "        end = round((i + 1) * avg_size)\n",
    "        subsets.append(items_copy[start:end])\n",
    "        start = end\n",
    "\n",
    "    return subsets\n",
    "\n",
    "def compute_c_S(subset: List[Tuple[Tuple[int, ...], float]]) -> float:\n",
    "    m = len(subset)\n",
    "    if m < 2:\n",
    "        return 0.0\n",
    "    mi = sum([t[1] for t in subset])\n",
    "    normalization = comb(m, 2)\n",
    "    c_S = mi / normalization\n",
    "    return c_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41d62129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((8, 9), 0.931028709319897), ((4, 10), 0.6410958759850565), ((5, 10), 0.5907776717062916), ((4, 5), 0.5799626247303435), ((0, 5), 0.5209933730247807), ((0, 10), 0.502056844971249), ((3, 11), 0.43487316378660523), ((0, 4), 0.41728668564205496), ((0, 12), 0.3866240867225108), ((0, 6), 0.28891003344387434), ((6, 10), 0.2852418262445884), ((0, 11), 0.269898283210396), ((3, 10), 0.2322709226991213), ((5, 7), 0.2164685261740522), ((1, 10), 0.21123926348835864), ((3, 5), 0.20729063848633933), ((1, 12), 0.2062452750753483), ((3, 7), 0.20204475267127053), ((4, 12), 0.19663827163017755), ((0, 1), 0.19643967402573503), ((4, 11), 0.19378406966204098), ((10, 11), 0.19246606381606357), ((5, 6), 0.18403579628875466), ((1, 11), 0.18135070540175446), ((2, 9), 0.1703450471091017), ((5, 11), 0.16785090011487114), ((0, 7), 0.15975926900547366), ((5, 12), 0.15759103878656688), ((2, 8), 0.15033728642724276), ((0, 3), 0.1488748160057054), ((6, 12), 0.1479880858538376), ((9, 11), 0.1367366496073399), ((10, 12), 0.13629749318485196), ((6, 7), 0.13195423041353616), ((1, 5), 0.1222887166166764), ((3, 6), 0.11439082620591146), ((3, 4), 0.10728232451330788), ((7, 10), 0.10170115127385815), ((6, 9), 0.09842845869186423), ((6, 8), 0.09734162241128397), ((1, 6), 0.08949471237535711), ((7, 11), 0.08494937415472092), ((3, 12), 0.08055377312687684), ((1, 3), 0.08003641650421756), ((9, 10), 0.0712267155190025), ((11, 12), 0.07099055636675322), ((4, 7), 0.07043910271185716), ((0, 2), 0.06868158487505216), ((2, 6), 0.06746976513430614), ((4, 6), 0.06376506251859881), ((1, 4), 0.06362968930453805), ((7, 8), 0.058893205296449036), ((5, 8), 0.058770617155915694), ((8, 10), 0.05642042018404414), ((1, 2), 0.05243789566479817), ((8, 12), 0.04245295653842396), ((0, 8), 0.042207912797761704), ((5, 9), 0.03635884978917758), ((7, 9), 0.03389430571442498), ((6, 11), 0.030542310310236243), ((1, 9), 0.028131994737417454), ((9, 12), 0.020059641530399297), ((3, 9), 0.019915737813423373), ((7, 12), 0.008919881885946612), ((2, 11), 0.0057914261660552135), ((4, 9), 0.005315073209462451), ((0, 9), 0.0), ((1, 7), 0.0), ((1, 8), 0.0), ((2, 3), 0.0), ((2, 4), 0.0), ((2, 5), 0.0), ((2, 7), 0.0), ((2, 10), 0.0), ((2, 12), 0.0), ((3, 8), 0.0), ((4, 8), 0.0), ((8, 11), 0.0)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    PairList = List[Tuple[Tuple[int, int], float]]\n",
    "    pairs = compute_all_pairwise_mi(X, feature_names=list(df.columns[:-1]), random_state=42, n_neighbors=3, n_jobs=2)\n",
    "    print(pairs)\n",
    "\n",
    "    top_2_list = select_top_pairs(pairs, top_n=10, mode='absolute', return_type='list')\n",
    "    #print(top_list)\n",
    "\n",
    "    # If you have compact list produced earlier:\n",
    "    top_2_df = select_top_pairs(pairs, top_n=10, mode='largest', feature_names=list(df.columns[:-1]), return_type='df')\n",
    "    #print(top_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "238ace31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 286 triplets (n_features=13) with k=4 using n_jobs=4...\n",
      "          S_idx                           S_names        mi    abs_mi\n",
      "0    (0, 1, 11)        (MDEC-23, MATS2v, VE3_Dzi)  0.666439  0.666439\n",
      "1    (1, 3, 10)      (MATS2v, VE3_Dt, SpMax5_Bhv)  0.664592  0.664592\n",
      "2    (3, 8, 10)      (VE3_Dt, GATS8e, SpMax5_Bhv)  0.603316  0.603316\n",
      "3     (0, 1, 3)         (MDEC-23, MATS2v, VE3_Dt)  0.581498  0.581498\n",
      "4    (0, 2, 11)        (MDEC-23, ATSC8s, VE3_Dzi)  0.569993  0.569993\n",
      "5    (1, 9, 11)         (MATS2v, GATS8s, VE3_Dzi)  0.559539  0.559539\n",
      "6    (0, 9, 11)        (MDEC-23, GATS8s, VE3_Dzi)  0.547544  0.547544\n",
      "7    (0, 8, 11)        (MDEC-23, GATS8e, VE3_Dzi)  0.535994  0.535994\n",
      "8     (1, 3, 4)       (MATS2v, VE3_Dt, CrippenMR)  0.532519  0.532519\n",
      "9   (1, 10, 11)     (MATS2v, SpMax5_Bhv, VE3_Dzi)  0.524398  0.524398\n",
      "10    (1, 3, 9)          (MATS2v, VE3_Dt, GATS8s)  0.523967  0.523967\n",
      "11   (4, 9, 11)      (CrippenMR, GATS8s, VE3_Dzi)  0.523726  0.523726\n",
      "12   (3, 9, 10)      (VE3_Dt, GATS8s, SpMax5_Bhv)  0.500235  0.500235\n",
      "13   (1, 4, 11)      (MATS2v, CrippenMR, VE3_Dzi)  0.498900  0.498900\n",
      "14   (1, 2, 11)         (MATS2v, ATSC8s, VE3_Dzi)  0.487622  0.487622\n",
      "15   (0, 4, 11)     (MDEC-23, CrippenMR, VE3_Dzi)  0.484284  0.484284\n",
      "16   (1, 8, 11)         (MATS2v, GATS8e, VE3_Dzi)  0.475337  0.475337\n",
      "17  (9, 10, 11)     (GATS8s, SpMax5_Bhv, VE3_Dzi)  0.461798  0.461798\n",
      "18    (1, 2, 3)          (MATS2v, ATSC8s, VE3_Dt)  0.460676  0.460676\n",
      "19   (2, 4, 11)      (ATSC8s, CrippenMR, VE3_Dzi)  0.460091  0.460091\n",
      "20   (4, 8, 11)      (CrippenMR, GATS8e, VE3_Dzi)  0.457332  0.457332\n",
      "21   (2, 3, 10)      (ATSC8s, VE3_Dt, SpMax5_Bhv)  0.452172  0.452172\n",
      "22    (0, 2, 3)         (MDEC-23, ATSC8s, VE3_Dt)  0.444097  0.444097\n",
      "23    (1, 3, 8)          (MATS2v, VE3_Dt, GATS8e)  0.441705  0.441705\n",
      "24    (0, 3, 8)         (MDEC-23, VE3_Dt, GATS8e)  0.426669  0.426669\n",
      "25   (3, 6, 10)  (VE3_Dt, SpMin1_Bhs, SpMax5_Bhv)  0.424477  0.424477\n",
      "26   (1, 6, 11)     (MATS2v, SpMin1_Bhs, VE3_Dzi)  0.410767  0.410767\n",
      "27    (1, 3, 6)      (MATS2v, VE3_Dt, SpMin1_Bhs)  0.407568  0.407568\n",
      "28   (0, 4, 10)  (MDEC-23, CrippenMR, SpMax5_Bhv)  0.403152  0.403152\n",
      "29    (0, 3, 9)         (MDEC-23, VE3_Dt, GATS8s)  0.397480  0.397480\n",
      "30   (4, 6, 11)  (CrippenMR, SpMin1_Bhs, VE3_Dzi)  0.395991  0.395991\n",
      "31    (3, 4, 8)       (VE3_Dt, CrippenMR, GATS8e)  0.388002  0.388002\n",
      "32    (3, 4, 6)   (VE3_Dt, CrippenMR, SpMin1_Bhs)  0.364791  0.364791\n",
      "33   (6, 9, 11)     (SpMin1_Bhs, GATS8s, VE3_Dzi)  0.360796  0.360796\n",
      "34    (2, 8, 9)          (ATSC8s, GATS8e, GATS8s)  0.360150  0.360150\n",
      "35  (0, 10, 11)    (MDEC-23, SpMax5_Bhv, VE3_Dzi)  0.355749  0.355749\n",
      "36    (3, 6, 9)      (VE3_Dt, SpMin1_Bhs, GATS8s)  0.354479  0.354479\n",
      "37   (0, 3, 10)     (MDEC-23, VE3_Dt, SpMax5_Bhv)  0.353906  0.353906\n",
      "38    (0, 3, 6)     (MDEC-23, VE3_Dt, SpMin1_Bhs)  0.350707  0.350707\n",
      "39   (2, 9, 11)         (ATSC8s, GATS8s, VE3_Dzi)  0.347654  0.347654\n",
      "40   (0, 6, 11)    (MDEC-23, SpMin1_Bhs, VE3_Dzi)  0.345461  0.345461\n",
      "41   (3, 4, 10)   (VE3_Dt, CrippenMR, SpMax5_Bhv)  0.334158  0.334158\n",
      "42  (8, 10, 11)     (GATS8e, SpMax5_Bhv, VE3_Dzi)  0.327885  0.327885\n",
      "43   (0, 3, 11)        (MDEC-23, VE3_Dt, VE3_Dzi)  0.325402  0.325402\n",
      "44   (8, 9, 11)         (GATS8e, GATS8s, VE3_Dzi)  0.320712  0.320712\n",
      "45    (2, 3, 4)       (ATSC8s, VE3_Dt, CrippenMR)  0.319404  0.319404\n",
      "46    (3, 6, 8)      (VE3_Dt, SpMin1_Bhs, GATS8e)  0.318118  0.318118\n",
      "47   (0, 1, 10)     (MDEC-23, MATS2v, SpMax5_Bhv)  0.316258  0.316258\n",
      "48    (3, 4, 9)       (VE3_Dt, CrippenMR, GATS8s)  0.313755  0.313755\n",
      "49    (0, 3, 4)      (MDEC-23, VE3_Dt, CrippenMR)  0.304706  0.304706\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    TripletList = List[Tuple[Tuple[int,int,int], float]]\n",
    "    triplets = compute_all_triplet_mi(X, feature_names=list(df.columns[:-1]), k=4, to_bits=False, n_jobs=4, verbose=True)\n",
    "    #print(triplets)\n",
    "\n",
    "    top_3_list = select_top_triplets(triplets, top_n=50, mode='absolute', return_type='list')\n",
    "    #print(top_list)\n",
    "\n",
    "    # If you have compact list produced earlier:\n",
    "    top_3_df = select_top_triplets(triplets, top_n=50, mode='largest', feature_names=list(df.columns[:-1]), return_type='df')\n",
    "    print(top_3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0be5b376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 1: [((8, 9), 0.931028709319897), ((0, 5), 0.5209933730247807)]\n",
      "Computed c_S for subset: 1.4520220823446777\n",
      "Subset 2: [((4, 5), 0.5799626247303435), ((0, 6), 0.28891003344387434), ((5, 10), 0.5907776717062916)]\n",
      "Computed c_S for subset: 0.48655010996016984\n",
      "Subset 3: [((4, 10), 0.6410958759850565), ((3, 11), 0.43487316378660523), ((0, 12), 0.3866240867225108)]\n",
      "Computed c_S for subset: 0.48753104216472415\n",
      "Subset 4: [((0, 10), 0.502056844971249), ((0, 4), 0.41728668564205496)]\n",
      "Computed c_S for subset: 0.919343530613304\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    set = create_set(\n",
    "        k='2',\n",
    "        top_pairs=top_2_list,\n",
    "        top_triplets=top_3_list\n",
    "    )\n",
    "    subsets = divide_into_subsets(set, num_subsets=4)\n",
    "\n",
    "    for i, s in enumerate(subsets):\n",
    "        print(f\"Subset {i+1}: {s}\")\n",
    "        c_s = compute_c_S(s)\n",
    "        print(f\"Computed c_S for subset: {c_s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f9c5c",
   "metadata": {},
   "source": [
    "## Alpha calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4363ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Rt(x: Sequence[float], c_s: Dict[Tuple[int, ...], float], _lambda: float) -> float:\n",
    "    # --- quadratic sums ---\n",
    "    sum_x2 = sum(xi**2 for xi in x)\n",
    "    sum_c2 = sum(ci**2 for ci in c_s.values())\n",
    "\n",
    "    # --- quartic sums ---\n",
    "    sum_x4 = sum(xi**4 for xi in x)\n",
    "    sum_c4 = sum(ci**4 for ci in c_s.values())\n",
    "\n",
    "    # doublets contributions\n",
    "    doublet_contribution = 0\n",
    "\n",
    "    # triplets contributions\n",
    "    triplet_contribution = 0\n",
    "\n",
    "    # --- Rt ---\n",
    "    Rt = ((1 - _lambda)**2) * (sum_x2 + 2 * sum_c2) + (_lambda**2) * (sum_x4 + 2 * sum_c4 + doublet_contribution + triplet_contribution)\n",
    "\n",
    "    return Rt\n",
    "\n",
    "def make_alpha1(x: Sequence[float], c_s: Dict[Tuple[int, ...], float], _lambda: float) -> float:\n",
    "    sum_x2, sum_c2 = 0, 0\n",
    "    sum_x2 = sum(xi**2 for xi in x)\n",
    "    sum_c2 = sum(ci**2 for ci in c_s.values())\n",
    "\n",
    "    # prefactor from commutator norm (paper-corrected)\n",
    "    alpha1 = -(1/4) * (sum_x2 + 2 * sum_c2)\n",
    "\n",
    "    Rt = make_Rt(x, c_s, _lambda)\n",
    "\n",
    "    return alpha1 / Rt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e531b5",
   "metadata": {},
   "source": [
    "# Gauge potential A(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0d0c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_A_circuit(n_qubits: int, x: Sequence[float], subsets: Sequence[Tuple[int, ...]], c_s: Dict[Tuple[int, ...], float], T: float) -> QuantumCircuit:\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    # Initialize to |+> on all qubits (ground state of X-field Hamiltonian)\n",
    "    qc.h(range(n_qubits))\n",
    "\n",
    "    pauli_labels = []\n",
    "    coeffs = []\n",
    "\n",
    "    # single-body term\n",
    "    for i, x_i in enumerate(x):\n",
    "        label = ['I'] * n_qubits\n",
    "        label[i] = 'Y'\n",
    "        pauli_labels.append(''.join(label))\n",
    "        coeffs.append(x_i)\n",
    "\n",
    "    \n",
    "    # multi-body terms\n",
    "    for S in subsets:\n",
    "        subset = tuple(S)\n",
    "        if subset == () or subset is None:\n",
    "            continue\n",
    "        #if len(subset) == 1:\n",
    "            #coef = float(c_s.get(subset, 0.0))\n",
    "            #if coef != 0.0:\n",
    "                #single_body_term(qc, subset[0], coef, dt)\n",
    "        else:\n",
    "            coef = float(c_s.get(subset, 0.0))\n",
    "            if coef != 0.0:\n",
    "                if any((idx < 0 or idx >= n_qubits) for idx in subset):\n",
    "                    raise IndexError(\"subset contains invalid qubit index\")\n",
    "                for i in S:\n",
    "                    label = ['I']*n_qubits\n",
    "                    label[i] = 'Y'\n",
    "                    for j in S:\n",
    "                        if j != i:\n",
    "                            label[j] = 'Z'\n",
    "                pauli_labels.append(''.join(label))\n",
    "                coeffs.append(coef)\n",
    "    \n",
    "    def alpha(t: float, T: float) -> float:\n",
    "        _lambda = np.sin((np.pi*np.sin((np.pi*t)/2*T)**2)/2)**2\n",
    "        return make_alpha1(x, c_s, _lambda)\n",
    "    \n",
    "    _alpha = alpha(delta_t, T)\n",
    "    # prefactor 2*alpha*(A*B' - B*A')\n",
    "    def prefactor(alpha: float, t: float, T: float)-> float:\n",
    "        A = np.sin((np.pi*np.sin((np.pi*t)/2*T)**2)/2)**2\n",
    "        B = np.cos((np.pi*np.sin((np.pi*t)/2*T)**2)/2)**2\n",
    "        A_prime = (np.pi**2/T) * np.sin((np.pi*t)/T) * np.sin((np.pi*t)**2/(2*T**2)) * np.cos((np.pi*t)**2/(2*T**2))\n",
    "        B_prime = -(np.pi**2/T) * np.sin((np.pi*t)/T) * np.sin((np.pi*t)**2/(2*T**2)) * np.cos((np.pi*t)**2/(2*T**2))\n",
    "        return 2*_alpha*(A*B_prime - B*A_prime)\n",
    "\n",
    "    # Build SparsePauliOp\n",
    "    ham_0 = SparsePauliOp(pauli_labels, np.array(coeffs))\n",
    "    ham = prefactor(_alpha, delta_t, T) * ham_0\n",
    "\n",
    "    # Synthesis method\n",
    "    synthesis = SuzukiTrotter(order=2, reps=1, insert_barriers=False, preserve_order=True) \n",
    "\n",
    "    # Build the evolution gate\n",
    "    evo = PauliEvolutionGate(ham, time=T, synthesis=synthesis)\n",
    "\n",
    "    # Append the evolution gate to the circuit\n",
    "    qc.append(evo, range(n_qubits))\n",
    "\n",
    "    return qc    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461eab0",
   "metadata": {},
   "source": [
    "### test: gauge potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c636fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ┌───┐┌────────────────────────────────────────────────────────────┐\n",
      "q_0: ┤ H ├┤0                                                           ├\n",
      "     ├───┤│                                                            │\n",
      "q_1: ┤ H ├┤1                                                           ├\n",
      "     ├───┤│  exp(-it (YIII + IYII + IIYI + IIIY + ZYII + IZZY))(0.005) │\n",
      "q_2: ┤ H ├┤2                                                           ├\n",
      "     ├───┤│                                                            │\n",
      "q_3: ┤ H ├┤3                                                           ├\n",
      "     └───┘└────────────────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1) toy example: 4 qubits\n",
    "    n_q = 4\n",
    "    # example feature vector x (mapped to single Z fields)\n",
    "    x = [0.5, -0.7, 0.0, 0.2]\n",
    "    # example subsets: pair (0,1), triplet (1,2,3)\n",
    "    subsets = [(0,1), (1,2,3)]\n",
    "    # example c_S coefficients (these would come from your MI computations)\n",
    "    c_s = {\n",
    "        (0,1): 0.9,         # two-body coupling strength\n",
    "        (1,2,3): 0.15       # three-body coupling strength\n",
    "    }\n",
    "\n",
    "    circ = build_A_circuit(n_q, x, subsets, c_s, T)\n",
    "    print(circ.draw(output=\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32773fe",
   "metadata": {},
   "source": [
    "# Measurement (Observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "912670da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_observables(n_qubits: int, subsets: Optional[Sequence[Tuple[int, ...]]] = None, K: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    Build a list of SparsePauliOp observables in the order:\n",
    "      [Z_0, Z_1, ..., Z_{n-1}, then all 2-body in subsets with |S|=2, ..., up to K]\n",
    "    \"\"\"\n",
    "\n",
    "    subsets = [tuple(s) for s in subsets]\n",
    "    observables = []\n",
    "    names = []\n",
    "\n",
    "    # singles\n",
    "    for i in range(n_qubits):\n",
    "        observables.append(SparsePauliOp.from_list([( \"I\"*i + \"Z\" + \"I\"*(n_qubits-i-1), 1.0 )]))\n",
    "        names.append(f\"Z_{i}\")\n",
    "\n",
    "    # k-body grouped by increasing k\n",
    "    for k in range(2, K + 1):\n",
    "        for S in subsets:\n",
    "            if len(S) == k:\n",
    "                p = [\"I\"]*n_qubits\n",
    "                for j in S: p[j]=\"Z\"\n",
    "                observables.append(SparsePauliOp.from_list([(\"\".join(p), 1.0)]))\n",
    "                names.append(\"Z_\" + \"_\".join(map(str, S)))\n",
    "\n",
    "    return observables, names\n",
    "\n",
    "def transpilation_setup(backend: Optional[str] = None, optimization_level: int = 3):\n",
    "    backend = backend or AerSimulator(shots=4096)\n",
    "    backend.options.seed_simulator = 42\n",
    "    backend.options.seed_transpiler = 42\n",
    "    estimator = Estimator(mode=backend)\n",
    "\n",
    "    pm = generate_preset_pass_manager(backend=backend, optimization_level=optimization_level)\n",
    "    return estimator, pm\n",
    "\n",
    "\n",
    "def quantum_features_via_estimator(qc: QuantumCircuit, n_qubits: int, subsets: Optional[Sequence[Tuple[int, ...]]] = None,\n",
    "                                   K: Optional[int] = None,\n",
    "                                   estimator=None,\n",
    "                                   run_options: Optional[Dict] = None):\n",
    "    \n",
    "    estimator, pm = transpilation_setup()\n",
    "\n",
    "    observables, names = build_feature_observables(n_qubits, subsets=subsets, K=K)\n",
    "\n",
    "    # Estimator supports batching: circuits list must align with observables list.\n",
    "    circuits = [qc] * len(observables)\n",
    "    circuits_transpiled = [pm.run(circ) for circ in circuits]\n",
    "\n",
    "    pubs = [(circ, [obs]) for circ, obs in zip(circuits_transpiled, observables)]\n",
    "    job = estimator.run(pubs)\n",
    "    res = job.result()\n",
    "    ev_list = []\n",
    "    for pub_res in res:\n",
    "        # pub_res.data.evs is typically array-like\n",
    "        try:\n",
    "            evs_pub = np.asarray(pub_res.data.evs).reshape(-1)\n",
    "        except Exception:\n",
    "            # Some runtimes may return nested structures; attempt alternative accesses\n",
    "            evs_pub = np.asarray(getattr(pub_res, \"values\", getattr(pub_res, \"data\", {}).get(\"evs\", []))).reshape(-1)\n",
    "        ev_list.extend(evs_pub.tolist())\n",
    "    evs = np.array(ev_list)\n",
    "\n",
    "    x_tilde = evs.copy()\n",
    "    meta = {'names': names, 'values': x_tilde}\n",
    "    return x_tilde, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03fd4bf",
   "metadata": {},
   "source": [
    "### test: measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6642b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: ['Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_0_1', 'Z_0_2', 'Z_1_2_3']\n",
      "x_tilde: [-0.01269531  0.01611328 -0.02099609 -0.01367188 -0.00976562 -0.01757812\n",
      "  0.00439453]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # toy example: 4 qubits\n",
    "    n_q = 4\n",
    "    # example feature vector x (mapped to single Z fields)\n",
    "    x = [0.5, -0.7, 0.0, 0.3]\n",
    "    # example subsets: pair (0,1), triplet (1,2,3)\n",
    "    subsets = [(0,1), (0,2), (1,2,3)]\n",
    "    # example c_S coefficients (these would come from your MI computations)\n",
    "    c_s = {\n",
    "        (0,1): 0.9,         # two-body coupling strength\n",
    "        (1,2,3): 0.15,       # three-body coupling strength\n",
    "        (0,2): 0.4        # another two-body coupling\n",
    "    }\n",
    "\n",
    "    circ = build_A_circuit(n_q, x, subsets, c_s, T)\n",
    "\n",
    "    # If you want to measure singles + all 2-body + all 3-body:\n",
    "    x_tilde, meta = quantum_features_via_estimator(circ, n_q, subsets, K=3)\n",
    "    print(\"feature names:\", meta['names'])\n",
    "    print(\"x_tilde:\", x_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf5832",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43402f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(X, y):\n",
    "    rscv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "\n",
    "    metrics = {\n",
    "        'AUC': [],\n",
    "        'F1 Macro': [],\n",
    "        'Precision Macro': [],\n",
    "        'Recall Macro': [],\n",
    "        'Accuracy': []\n",
    "    }\n",
    "    for fold, (train_id, test_id) in enumerate(rscv.split(X,y)):\n",
    "\n",
    "        x_train = X[train_id]\n",
    "        x_test = X[test_id]\n",
    "        y_train = y[train_id]\n",
    "        y_test = y[test_id]\n",
    "\n",
    "    x_train, x_test = data_preprocessing(x_train, x_test)\n",
    "    classifier = GradientBoostingClassifier(n_estimators=1000, random_state=42)\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    y_proba = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    metrics['AUC'].append(roc_auc_score(y_test, y_proba))\n",
    "    metrics['F1 Macro'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "    metrics['Precision Macro'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "    metrics['Recall Macro'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "    metrics['Accuracy'].append(accuracy_score(y_test, y_pred))    \n",
    "\n",
    "    median_metrics = {k: np.median(v) for k, v in metrics.items()}\n",
    "\n",
    "    return median_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f740c980",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a014f",
   "metadata": {},
   "source": [
    "### Classical result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d68b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6443\n",
      "F1 Macro: 0.6222\n",
      "Precision Macro: 0.6561\n",
      "Recall Macro: 0.6166\n",
      "Accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "metrics_original = classification(X, y)\n",
    "for k, v in metrics_original.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89045a3",
   "metadata": {},
   "source": [
    "### Quantum result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3296bb3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TranspilerError",
     "evalue": "'[PhysicalQubit(1202)] not in Target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTranspilerError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passmanager.py:464\u001b[0m, in \u001b[0;36m_replace_error.<locals>.wrapper\u001b[1;34m(*meth_args, **meth_kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmeth_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmeth_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PassManagerError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passmanager.py:226\u001b[0m, in \u001b[0;36mPassManager.run\u001b[1;34m(self, circuits, output_name, callback, num_processes)\u001b[0m\n\u001b[0;32m    224\u001b[0m     callback \u001b[38;5;241m=\u001b[39m _legacy_style_callback(callback)\n\u001b[1;32m--> 226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_programs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\passmanager.py:249\u001b[0m, in \u001b[0;36mBasePassManager.run\u001b[1;34m(self, in_programs, callback, num_processes, property_set, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(in_programs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_run_in_parallel(num_processes):\n\u001b[1;32m--> 249\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_run_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43min_programs\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(in_programs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list:\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\passmanager.py:250\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(in_programs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_run_in_parallel(num_processes):\n\u001b[0;32m    249\u001b[0m     out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 250\u001b[0m         \u001b[43m_run_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m program \u001b[38;5;129;01min\u001b[39;00m in_programs\n\u001b[0;32m    252\u001b[0m     ]\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(in_programs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list:\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\passmanager.py:310\u001b[0m, in \u001b[0;36m_run_workflow\u001b[1;34m(program, pass_manager, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m passmanager_ir \u001b[38;5;241m=\u001b[39m pass_manager\u001b[38;5;241m.\u001b[39m_passmanager_frontend(\n\u001b[0;32m    307\u001b[0m     input_program\u001b[38;5;241m=\u001b[39mprogram,\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    309\u001b[0m )\n\u001b[1;32m--> 310\u001b[0m passmanager_ir, final_state \u001b[38;5;241m=\u001b[39m \u001b[43mflow_controller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassmanager_ir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassmanager_ir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPassManagerState\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkflow_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperty_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPropertySet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# The `property_set` has historically been returned as a mutable attribute on `PassManager`\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# This makes us non-reentrant (though `PassManager` would be dependent on its internal tasks to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# be re-entrant if that was required), but is consistent with previous interfaces.  We're still\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# safe to be called in a serial loop, again assuming internal tasks are re-runnable.  The\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# conversion to the backend language is also allowed to use the property set, so it must be set\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# before calling it.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\base_tasks.py:218\u001b[0m, in \u001b[0;36mBaseController.execute\u001b[1;34m(self, passmanager_ir, state, callback)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     passmanager_ir, state \u001b[38;5;241m=\u001b[39m \u001b[43mnext_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassmanager_ir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassmanager_ir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;66;03m# Sending the object through the generator implies the custom controllers\u001b[39;00m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# can always rely on the latest data to choose the next task to run.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\base_tasks.py:218\u001b[0m, in \u001b[0;36mBaseController.execute\u001b[1;34m(self, passmanager_ir, state, callback)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     passmanager_ir, state \u001b[38;5;241m=\u001b[39m \u001b[43mnext_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassmanager_ir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassmanager_ir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;66;03m# Sending the object through the generator implies the custom controllers\u001b[39;00m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# can always rely on the latest data to choose the next task to run.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\basepasses.py:195\u001b[0m, in \u001b[0;36mTransformationPass.execute\u001b[1;34m(self, passmanager_ir, state, callback)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    191\u001b[0m     passmanager_ir: PassManagerIR,\n\u001b[0;32m    192\u001b[0m     state: PassManagerState,\n\u001b[0;32m    193\u001b[0m     callback: Callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    194\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[PassManagerIR, PassManagerState]:\n\u001b[1;32m--> 195\u001b[0m     new_dag, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpassmanager_ir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassmanager_ir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mworkflow_status\u001b[38;5;241m.\u001b[39mprevious_run \u001b[38;5;241m==\u001b[39m RunState\u001b[38;5;241m.\u001b[39mSUCCESS:\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\passmanager\\base_tasks.py:98\u001b[0m, in \u001b[0;36mGenericPass.execute\u001b[1;34m(self, passmanager_ir, state, callback)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mworkflow_status\u001b[38;5;241m.\u001b[39mcompleted_passes:\n\u001b[1;32m---> 98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpassmanager_ir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     run_state \u001b[38;5;241m=\u001b[39m RunState\u001b[38;5;241m.\u001b[39mSUCCESS\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passes\\utils\\control_flow.py:63\u001b[0m, in \u001b[0;36mtrivial_recurse.<locals>.out\u001b[1;34m(self, dag)\u001b[0m\n\u001b[0;32m     60\u001b[0m         dag\u001b[38;5;241m.\u001b[39msubstitute_node(\n\u001b[0;32m     61\u001b[0m             node, map_blocks(bound_wrapped_method, node\u001b[38;5;241m.\u001b[39mop), propagate_condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passes\\optimization\\optimize_1q_decomposition.py:214\u001b[0m, in \u001b[0;36mOptimize1qGatesDecomposition.run\u001b[1;34m(self, dag)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the Optimize1qGatesDecomposition pass on `dag`.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    DAGCircuit: the optimized DAG.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m \u001b[43meuler_one_qubit_decomposer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_1q_gates_decomposition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mglobal_decomposers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_global_decomposers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasis_gates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_basis_gates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dag\n",
      "\u001b[1;31mTranspilerError\u001b[0m: '[PhysicalQubit(1202)] not in Target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTranspilerError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m circ \u001b[38;5;241m=\u001b[39m build_A_circuit(n_features, x, subsets, c_s_dict, T)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# call your estimator - must return (x_tilde, meta)\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m x_tilde, meta \u001b[38;5;241m=\u001b[39m \u001b[43mquantum_features_via_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure x_tilde is a 1D array\u001b[39;00m\n\u001b[0;32m     18\u001b[0m x_tilde \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x_tilde)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 48\u001b[0m, in \u001b[0;36mquantum_features_via_estimator\u001b[1;34m(qc, n_qubits, subsets, K, estimator, run_options)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Estimator supports batching: circuits list must align with observables list.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m circuits \u001b[38;5;241m=\u001b[39m [qc] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(observables)\n\u001b[1;32m---> 48\u001b[0m circuits_transpiled \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     50\u001b[0m pubs \u001b[38;5;241m=\u001b[39m [(circ, [obs]) \u001b[38;5;28;01mfor\u001b[39;00m circ, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(circuits_transpiled, observables)]\n\u001b[0;32m     51\u001b[0m job \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mrun(pubs)\n",
      "Cell \u001b[1;32mIn[53], line 48\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Estimator supports batching: circuits list must align with observables list.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m circuits \u001b[38;5;241m=\u001b[39m [qc] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(observables)\n\u001b[1;32m---> 48\u001b[0m circuits_transpiled \u001b[38;5;241m=\u001b[39m [\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcirc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m circ \u001b[38;5;129;01min\u001b[39;00m circuits]\n\u001b[0;32m     50\u001b[0m pubs \u001b[38;5;241m=\u001b[39m [(circ, [obs]) \u001b[38;5;28;01mfor\u001b[39;00m circ, obs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(circuits_transpiled, observables)]\n\u001b[0;32m     51\u001b[0m job \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mrun(pubs)\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passmanager.py:441\u001b[0m, in \u001b[0;36mStagedPassManager.run\u001b[1;34m(self, circuits, output_name, callback, num_processes)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    435\u001b[0m     circuits: _CircuitsT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m     num_processes: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    439\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CircuitsT:\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_passmanager()\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\qiskit\\transpiler\\passmanager.py:466\u001b[0m, in \u001b[0;36m_replace_error.<locals>.wrapper\u001b[1;34m(*meth_args, **meth_kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\u001b[38;5;241m*\u001b[39mmeth_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmeth_kwargs)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PassManagerError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TranspilerError(ex\u001b[38;5;241m.\u001b[39mmessage) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mTranspilerError\u001b[0m: '[PhysicalQubit(1202)] not in Target'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Prepare subsets and c_s mapping (from your earlier top_2_list)\n",
    "    subsets = [tuple(t[0]) for t in top_2_list]   # e.g. [(0,1), (2,3), ...]\n",
    "    c_s_dict = { tuple(t[0]) : float(t[1]) for t in top_2_list }\n",
    "\n",
    "    X_tilde_list = []\n",
    "\n",
    "    for idx, x in enumerate(X):\n",
    "        # build circuit using dict-form c_s\n",
    "        circ = build_A_circuit(n_features, x, subsets, c_s_dict, T)\n",
    "\n",
    "        # call your estimator - must return (x_tilde, meta)\n",
    "        x_tilde, meta = quantum_features_via_estimator(circ, n_features, subsets, K=3)\n",
    "\n",
    "        # Ensure x_tilde is a 1D array\n",
    "        x_tilde = np.asarray(x_tilde).reshape(-1)\n",
    "\n",
    "        X_tilde_list.append(x_tilde)\n",
    "    \n",
    "    X_tilde = np.array(X_tilde_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e485231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5000\n",
      "F1 Macro: 0.4035\n",
      "Precision Macro: 0.3382\n",
      "Recall Macro: 0.5000\n",
      "Accuracy: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jiriv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "metrics_quantum = classification(X_tilde, y)\n",
    "for k, v in metrics_quantum.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f752b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DT_venv)",
   "language": "python",
   "name": "dt_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
