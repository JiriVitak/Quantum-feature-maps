{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e9c7f6",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6de40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil, pi, sin\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.quantum_info import SparsePauliOp, Pauli, Statevector\n",
    "from qiskit.circuit.library import PauliEvolutionGate\n",
    "from qiskit.synthesis import SuzukiTrotter\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime import EstimatorV2\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, balanced_accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c370cc",
   "metadata": {},
   "source": [
    "Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14e3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUBITS = 13            # Number of qubits\n",
    "TAU = 30e-9              # 30 ns (seconds)\n",
    "A0 = 2 * pi * 15e9       # rad/s\n",
    "B0 = 2 * pi * 11e9       # rad/s\n",
    "#REPS = 4\n",
    "#M = 4\n",
    "REPS = 64\n",
    "M = ceil(2000 / REPS)    # -> 32 slices when REPS=64\n",
    "DELTA_T = TAU / M\n",
    "ORDER = 2                # Suzuki-Trotter order\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5\n",
    "\n",
    "# added by Jiri\n",
    "OPTIMIZATION_LEVEL = 0\n",
    "SHOTS = 1024\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7080f6",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6fc5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "NonToxic    115\n",
      "Toxic        56\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDEC-23</th>\n",
       "      <th>MATS2v</th>\n",
       "      <th>ATSC8s</th>\n",
       "      <th>VE3_Dt</th>\n",
       "      <th>CrippenMR</th>\n",
       "      <th>SpMax7_Bhe</th>\n",
       "      <th>SpMin1_Bhs</th>\n",
       "      <th>C1SP2</th>\n",
       "      <th>GATS8e</th>\n",
       "      <th>GATS8s</th>\n",
       "      <th>SpMax5_Bhv</th>\n",
       "      <th>VE3_Dzi</th>\n",
       "      <th>VPC-4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.1757</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>-0.6667</td>\n",
       "      <td>-167.1241</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.4009</td>\n",
       "      <td>2.3109</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0229</td>\n",
       "      <td>1.0575</td>\n",
       "      <td>3.5545</td>\n",
       "      <td>-15.5940</td>\n",
       "      <td>4.1692</td>\n",
       "      <td>NonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5031</td>\n",
       "      <td>-0.1236</td>\n",
       "      <td>-16.5096</td>\n",
       "      <td>-16.2080</td>\n",
       "      <td>172.2000</td>\n",
       "      <td>3.3611</td>\n",
       "      <td>2.1117</td>\n",
       "      <td>2</td>\n",
       "      <td>1.7155</td>\n",
       "      <td>1.7013</td>\n",
       "      <td>3.6066</td>\n",
       "      <td>-14.3317</td>\n",
       "      <td>2.0821</td>\n",
       "      <td>NonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.5488</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>19.3467</td>\n",
       "      <td>-159.1796</td>\n",
       "      <td>173.4028</td>\n",
       "      <td>3.2705</td>\n",
       "      <td>2.0198</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>3.6441</td>\n",
       "      <td>-25.4493</td>\n",
       "      <td>2.8730</td>\n",
       "      <td>NonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.5929</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>-9.5672</td>\n",
       "      <td>-21.4416</td>\n",
       "      <td>177.2726</td>\n",
       "      <td>3.2748</td>\n",
       "      <td>2.0191</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>1.0298</td>\n",
       "      <td>3.6564</td>\n",
       "      <td>-19.6376</td>\n",
       "      <td>3.0444</td>\n",
       "      <td>NonToxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.7343</td>\n",
       "      <td>-0.0861</td>\n",
       "      <td>-11.8892</td>\n",
       "      <td>-2.0780</td>\n",
       "      <td>171.1315</td>\n",
       "      <td>3.4094</td>\n",
       "      <td>2.1664</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>3.5216</td>\n",
       "      <td>-8.2157</td>\n",
       "      <td>2.9469</td>\n",
       "      <td>NonToxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDEC-23  MATS2v   ATSC8s    VE3_Dt  CrippenMR  SpMax7_Bhe  SpMin1_Bhs  \\\n",
       "0  60.1757 -0.0231  -0.6667 -167.1241     0.0000      3.4009      2.3109   \n",
       "1  44.5031 -0.1236 -16.5096  -16.2080   172.2000      3.3611      2.1117   \n",
       "2  37.5488  0.0662  19.3467 -159.1796   173.4028      3.2705      2.0198   \n",
       "3  40.5929  0.0714  -9.5672  -21.4416   177.2726      3.2748      2.0191   \n",
       "4  52.7343 -0.0861 -11.8892   -2.0780   171.1315      3.4094      2.1664   \n",
       "\n",
       "   C1SP2  GATS8e  GATS8s  SpMax5_Bhv  VE3_Dzi   VPC-4     Class  \n",
       "0      4  1.0229  1.0575      3.5545 -15.5940  4.1692  NonToxic  \n",
       "1      2  1.7155  1.7013      3.6066 -14.3317  2.0821  NonToxic  \n",
       "2      8  0.6992  0.7828      3.6441 -25.4493  2.8730  NonToxic  \n",
       "3      6  0.9951  1.0298      3.6564 -19.6376  3.0444  NonToxic  \n",
       "4      2  0.7363  0.7427      3.5216  -8.2157  2.9469  NonToxic  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_save = \"Dataset/Toxicity-13F.csv\"\n",
    "\n",
    "def load_dataset(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(dataset_save)\n",
    "print(df['Class'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a3e0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "1    115\n",
      "0     56\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDEC-23</th>\n",
       "      <th>MATS2v</th>\n",
       "      <th>ATSC8s</th>\n",
       "      <th>VE3_Dt</th>\n",
       "      <th>CrippenMR</th>\n",
       "      <th>SpMax7_Bhe</th>\n",
       "      <th>SpMin1_Bhs</th>\n",
       "      <th>C1SP2</th>\n",
       "      <th>GATS8e</th>\n",
       "      <th>GATS8s</th>\n",
       "      <th>SpMax5_Bhv</th>\n",
       "      <th>VE3_Dzi</th>\n",
       "      <th>VPC-4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.1757</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>-0.6667</td>\n",
       "      <td>-167.1241</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.4009</td>\n",
       "      <td>2.3109</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0229</td>\n",
       "      <td>1.0575</td>\n",
       "      <td>3.5545</td>\n",
       "      <td>-15.5940</td>\n",
       "      <td>4.1692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5031</td>\n",
       "      <td>-0.1236</td>\n",
       "      <td>-16.5096</td>\n",
       "      <td>-16.2080</td>\n",
       "      <td>172.2000</td>\n",
       "      <td>3.3611</td>\n",
       "      <td>2.1117</td>\n",
       "      <td>2</td>\n",
       "      <td>1.7155</td>\n",
       "      <td>1.7013</td>\n",
       "      <td>3.6066</td>\n",
       "      <td>-14.3317</td>\n",
       "      <td>2.0821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.5488</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>19.3467</td>\n",
       "      <td>-159.1796</td>\n",
       "      <td>173.4028</td>\n",
       "      <td>3.2705</td>\n",
       "      <td>2.0198</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>3.6441</td>\n",
       "      <td>-25.4493</td>\n",
       "      <td>2.8730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.5929</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>-9.5672</td>\n",
       "      <td>-21.4416</td>\n",
       "      <td>177.2726</td>\n",
       "      <td>3.2748</td>\n",
       "      <td>2.0191</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>1.0298</td>\n",
       "      <td>3.6564</td>\n",
       "      <td>-19.6376</td>\n",
       "      <td>3.0444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.7343</td>\n",
       "      <td>-0.0861</td>\n",
       "      <td>-11.8892</td>\n",
       "      <td>-2.0780</td>\n",
       "      <td>171.1315</td>\n",
       "      <td>3.4094</td>\n",
       "      <td>2.1664</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>3.5216</td>\n",
       "      <td>-8.2157</td>\n",
       "      <td>2.9469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MDEC-23  MATS2v   ATSC8s    VE3_Dt  CrippenMR  SpMax7_Bhe  SpMin1_Bhs  \\\n",
       "0  60.1757 -0.0231  -0.6667 -167.1241     0.0000      3.4009      2.3109   \n",
       "1  44.5031 -0.1236 -16.5096  -16.2080   172.2000      3.3611      2.1117   \n",
       "2  37.5488  0.0662  19.3467 -159.1796   173.4028      3.2705      2.0198   \n",
       "3  40.5929  0.0714  -9.5672  -21.4416   177.2726      3.2748      2.0191   \n",
       "4  52.7343 -0.0861 -11.8892   -2.0780   171.1315      3.4094      2.1664   \n",
       "\n",
       "   C1SP2  GATS8e  GATS8s  SpMax5_Bhv  VE3_Dzi   VPC-4  Class  \n",
       "0      4  1.0229  1.0575      3.5545 -15.5940  4.1692      1  \n",
       "1      2  1.7155  1.7013      3.6066 -14.3317  2.0821      1  \n",
       "2      8  0.6992  0.7828      3.6441 -25.4493  2.8730      1  \n",
       "3      6  0.9951  1.0298      3.6564 -19.6376  3.0444      1  \n",
       "4      2  0.7363  0.7427      3.5216  -8.2157  2.9469      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map 'NonToxic' → 1, 'Toxic' → 0\n",
    "df['Class'] = df['Class'].apply(lambda v: 1 if str(v).strip().lower().startswith('non') else 0)\n",
    "print(df['Class'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16c54b",
   "metadata": {},
   "source": [
    "QFMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6b83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helper building functions for Hamiltonians\n",
    "# -------------------------\n",
    "\n",
    "def print_circuit_specs(circuit):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Quantum circuit {circuit.name} specifications\n",
    "    -----------------------------\n",
    "\n",
    "                    Depth: {circuit.depth()}\n",
    "                Gate count: {len(circuit)}\n",
    "        Nonlocal gate count: {circuit.num_nonlocal_gates()}\n",
    "            Gate breakdown: {\", \".join([f\"{k.upper()}: {v}\" for k, v in circuit.count_ops().items()])}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "def s_of_t(t, tau=TAU):\n",
    "    # s(t) = sin^2( (pi/2) * sin^2(pi t / (2 tau)) )\n",
    "    inner = sin(pi * t / (2 * tau)) ** 2\n",
    "    return sin((pi / 2) * inner) ** 2\n",
    "\n",
    "def A_of_t(t): \n",
    "    return A0 * (1.0 - s_of_t(t))\n",
    "\n",
    "def B_of_t(t): \n",
    "    return B0 * s_of_t(t)\n",
    "\n",
    "def build_HD(n):\n",
    "    #H_D = - sum_i X_i represented as a SparsePauliOp\n",
    "    labels = []\n",
    "    coeffs = []\n",
    "    for i in range(n):\n",
    "        s = ['I'] * n\n",
    "        s[i] = 'X'\n",
    "        labels.append(''.join(s))\n",
    "        coeffs.append(-1.0)\n",
    "    pauli_list = [Pauli(label) for label in labels]\n",
    "    return SparsePauliOp(pauli_list, coeffs)\n",
    "\n",
    "def build_HP_from_sample(x_std, Jij):\n",
    "    # Problem Hamiltonian HP(x) = sum_i hi Z_i + sum_{i<j} Jij Z_i Z_j\n",
    "    # where hi = x_i and Jij is correlation matrix entries.\n",
    "    n = len(x_std)\n",
    "    labels = []\n",
    "    coeffs = []\n",
    "    # local fields\n",
    "    for i in range(n):\n",
    "        s = ['I'] * n\n",
    "        s[i] = 'Z'\n",
    "        labels.append(''.join(s))\n",
    "        coeffs.append(float(x_std[i]))\n",
    "    # pairwise ZZ\n",
    "    for i, j in combinations(range(n), 2):\n",
    "        s = ['I'] * n\n",
    "        s[i] = 'Z'\n",
    "        s[j] = 'Z'\n",
    "        labels.append(''.join(s))\n",
    "        coeffs.append(float(Jij[i, j]))\n",
    "    pauli_list = [Pauli(label) for label in labels]\n",
    "    return SparsePauliOp(pauli_list, coeffs)\n",
    "\n",
    "# -------------------------\n",
    "# Quantum feature extraction\n",
    "# -------------------------\n",
    "def make_evolution_circuit(n_qubits, HP_op_time_dep_fn):\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "    # initial |+>^{n}\n",
    "    for q in range(n_qubits):\n",
    "        qc.h(q)\n",
    "\n",
    "    # Prebuild H_D (Pauli sum op)\n",
    "    HD_op = build_HD(n_qubits)\n",
    "\n",
    "    # Append m slices. For slice k (0..m-1) freeze at midpoint t_{k+1/2} = (k+0.5)*dt\n",
    "    for k in range(M):\n",
    "        t_mid = (k + 0.5) * DELTA_T\n",
    "        A = A_of_t(t_mid)\n",
    "        B = B_of_t(t_mid)\n",
    "        HP_mid = HP_op_time_dep_fn(k)\n",
    "\n",
    "        # H_slice = A * HD + B * HP_mid\n",
    "        H_slice = (A * HD_op) + (B * HP_mid)\n",
    "\n",
    "        evo_gate = PauliEvolutionGate(H_slice, time=DELTA_T, synthesis=SuzukiTrotter(order=ORDER, reps=REPS))\n",
    "        qc.append(evo_gate, qc.qubits)\n",
    "\n",
    "    return qc\n",
    "\n",
    "def statevector_expectation_z(statevec, qubit_index, n_qubits):\n",
    "    \"\"\"\n",
    "    Compute <Z_i> = sum_{basis states} |amp|^2 * (-1)^{bit_i}\n",
    "    Assumes standard integer index ordering where basis index 0 -> |00...0>.\n",
    "    We take qubit 0 -> leftmost in Pauli strings above, and map it to the most-significant bit:\n",
    "    bit = (index >> (n_qubits - 1 - qubit_index)) & 1\n",
    "    \"\"\"\n",
    "    probs = np.abs(statevec.data) ** 2\n",
    "    exp = 0.0\n",
    "    for idx, p in enumerate(probs):\n",
    "        bit = (idx >> (n_qubits - 1 - qubit_index)) & 1\n",
    "        exp += p * (1.0 if bit == 0 else -1.0)\n",
    "\n",
    "    return float(exp)\n",
    "\n",
    "def build_circuit_for_sample(x_std, Jij):\n",
    "    n = len(x_std)\n",
    "    HP_op = build_HP_from_sample(x_std, Jij)\n",
    "    qc = make_evolution_circuit(n, lambda k: HP_op)\n",
    "    return qc\n",
    "\n",
    "def _has_saved_statevector(qc):\n",
    "    for instr, _, _ in qc.data:\n",
    "        # instruction name can be 'save_statevector' or similar depending on version\n",
    "        name = getattr(instr, \"name\", \"\")\n",
    "        if name == \"save_statevector\" or \"save_statevector\" in name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def compute_quantum_features_aer_batch(X_std, Jij, batch_size=BATCH_SIZE, shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL):\n",
    "    n_samples = X_std.shape[0]\n",
    "    n_qubits = X_std.shape[1]\n",
    "    features = np.zeros((n_samples, n_qubits), dtype=float)\n",
    "\n",
    "    # Build circuits (do NOT call save_statevector here)\n",
    "    circuits = [build_circuit_for_sample(X_std[i], Jij) for i in range(n_samples)]\n",
    "\n",
    "    backend = AerSimulator(method=\"statevector\")\n",
    "\n",
    "    n_batches = (n_samples + batch_size - 1) // batch_size\n",
    "    with tqdm(total=n_samples, desc=\"Aer batch features\", unit=\"sample\", dynamic_ncols=True) as pbar:\n",
    "        for b in range(n_batches):\n",
    "            start = b * batch_size\n",
    "            end = min(start + batch_size, n_samples)\n",
    "            batch_circuits = []\n",
    "\n",
    "            # For this batch, ensure each circuit has exactly one save_statevector instruction\n",
    "            for i in range(start, end):\n",
    "                qc = circuits[i]\n",
    "                if not _has_saved_statevector(qc):\n",
    "                    qc.save_statevector()\n",
    "                batch_circuits.append(qc)\n",
    "\n",
    "            # Transpile and run this batch\n",
    "            transpiled = transpile(batch_circuits, backend=backend, optimization_level=optimization_level)\n",
    "            job = backend.run(transpiled, shots=shots)\n",
    "            result = job.result()\n",
    "\n",
    "            # Robust way to obtain experiment results list\n",
    "            res_list = getattr(result, \"results\", None)\n",
    "            if res_list is None:\n",
    "                # fallback to trying to collect data() for each experiment\n",
    "                res_list = []\n",
    "                for j in range(len(transpiled)):\n",
    "                    try:\n",
    "                        data_j = result.data(j)\n",
    "                        wrapper = type(\"R\", (), {\"data\": type(\"D\", (), {\"to_dict\": lambda: data_j})})()\n",
    "                        res_list.append(wrapper)\n",
    "                    except Exception:\n",
    "                        raise RuntimeError(\"Could not recover result list from Aer job result.\")\n",
    "\n",
    "            # iterate returned results and extract saved statevector for each local experiment\n",
    "            for local_j, res_exp in enumerate(res_list):\n",
    "                global_i = start + local_j\n",
    "\n",
    "                # Try common extraction patterns\n",
    "                amps = None\n",
    "                # 1) res_exp.data.to_dict() -> dict with 'statevector'\n",
    "                try:\n",
    "                    d = res_exp.data.to_dict() if hasattr(res_exp.data, \"to_dict\") else res_exp.data\n",
    "                    if isinstance(d, dict) and \"statevector\" in d:\n",
    "                        amps = np.asarray(d[\"statevector\"])\n",
    "                except Exception:\n",
    "                    amps = None\n",
    "\n",
    "                # 2) result.get_statevector(local_j)\n",
    "                if amps is None:\n",
    "                    try:\n",
    "                        sv = result.get_statevector(local_j)\n",
    "                        amps = np.asarray(sv.data) if hasattr(sv, \"data\") else np.asarray(sv)\n",
    "                    except Exception:\n",
    "                        amps = None\n",
    "\n",
    "                # 3) fallback: maybe res_exp.data is dict-like directly\n",
    "                if amps is None:\n",
    "                    try:\n",
    "                        if isinstance(res_exp.data, dict) and \"statevector\" in res_exp.data:\n",
    "                            amps = np.asarray(res_exp.data[\"statevector\"])\n",
    "                    except Exception:\n",
    "                        amps = None\n",
    "\n",
    "                if amps is None:\n",
    "                    raise RuntimeError(f\"Could not extract statevector for batch {b} sample {local_j} (global {global_i})\")\n",
    "\n",
    "                probs = np.abs(amps) ** 2\n",
    "                # compute <Z> per qubit\n",
    "                for q in range(n_qubits):\n",
    "                    exp = 0.0\n",
    "                    for idx_basis, p in enumerate(probs):\n",
    "                        bit = (idx_basis >> (n_qubits - 1 - q)) & 1\n",
    "                        exp += p * (1.0 if bit == 0 else -1.0)\n",
    "                    features[global_i, q] = exp\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "    return features\n",
    "\n",
    "def compute_quantum_features_aer(X_std, Jij, shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL):\n",
    "    n_samples = X_std.shape[0]\n",
    "    n_qubits = X_std.shape[1]\n",
    "    features = np.zeros((n_samples, n_qubits), dtype=float)\n",
    "\n",
    "    backend = AerSimulator(method=\"statevector\")\n",
    "\n",
    "    with tqdm(total=n_samples, desc=\"Aer features\", unit=\"sample\", dynamic_ncols=True) as pbar:\n",
    "        for i in range(n_samples):\n",
    "            qc = build_circuit_for_sample(X_std[i], Jij)\n",
    "            if not _has_saved_statevector(qc):\n",
    "                qc.save_statevector()\n",
    "\n",
    "            transpiled = transpile(qc, backend=backend, optimization_level=optimization_level)\n",
    "            if i == 0:\n",
    "                print_circuit_specs(transpiled)\n",
    "            job = backend.run(transpiled, shots=shots)\n",
    "            result = job.result()\n",
    "\n",
    "            # Extract statevector\n",
    "            try:\n",
    "                sv = result.get_statevector()\n",
    "                amps = np.asarray(sv.data) if hasattr(sv, \"data\") else np.asarray(sv)\n",
    "            except Exception:\n",
    "                data = result.data(0)\n",
    "                amps = np.asarray(data.get(\"statevector\"))\n",
    "\n",
    "            # Compute <Z> expectation per qubit\n",
    "            probs = np.abs(amps) ** 2\n",
    "            for q in range(n_qubits):\n",
    "                exp = 0.0\n",
    "                for idx_basis, p in enumerate(probs):\n",
    "                    bit = (idx_basis >> (n_qubits - 1 - q)) & 1\n",
    "                    exp += p * (1.0 if bit == 0 else -1.0)\n",
    "                features[i, q] = exp\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    return features\n",
    "\n",
    "def run_quantum_feature_extraction(X_std, Jij, n_qubits=N_QUBITS, shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL):\n",
    "    n_samples = X_std.shape[0]\n",
    "    features = np.zeros((n_samples, n_qubits), dtype=float)\n",
    "\n",
    "    simulator = AerSimulator(method=\"statevector\")\n",
    "    estimator = EstimatorV2(mode=simulator)\n",
    "    pass_manager = generate_preset_pass_manager(backend=simulator, optimization_level=optimization_level)\n",
    "\n",
    "    # Prebuild single-qubit Z observables (SparsePauliOp) for expectation readout\n",
    "    z_observables = []\n",
    "    for i in range(n_qubits): \n",
    "        s = ['I'] * n_qubits \n",
    "        s[i] = 'Z' \n",
    "        z_observables.append(SparsePauliOp([Pauli(''.join(s))], [1.0]))\n",
    "\n",
    "    with tqdm(total=n_samples, desc=\"Aer features\", unit=\"sample\", dynamic_ncols=True) as pbar:\n",
    "        for idx in range(n_samples):\n",
    "            qc = build_circuit_for_sample(X_std[i], Jij)\n",
    "            qc_transpiled = pass_manager.run(qc)\n",
    "\n",
    "            # Estimate <Z_i> for each qubit i\n",
    "            job = estimator.run([(qc_transpiled, z_observables)])\n",
    "            pub_result = job.result()[0]\n",
    "            features[idx, :] = pub_result.data.evs\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ------------------------- \n",
    "# Main experiment: CV loop \n",
    "# ------------------------- \n",
    "def run_experiment(X, y): \n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    metrics = { 'auc': [], 'f1': [], 'bal_acc': [], 'prec_0': [], 'rec_0': [], 'prec_1': [], 'rec_1': [] }\n",
    "\n",
    "    fold_idx = 0 \n",
    "    for train_idx, test_idx in skf.split(X, y): \n",
    "        fold_idx += 1 \n",
    "        Xtrain, Xtest = X[train_idx], X[test_idx] \n",
    "        ytrain, ytest = y[train_idx], y[test_idx]\n",
    "     \n",
    "        # preprocessing \n",
    "        imputer = SimpleImputer(strategy='median') \n",
    "        imputer.fit(Xtrain) \n",
    "        Xtrain_im = imputer.transform(Xtrain) \n",
    "        Xtest_im = imputer.transform(Xtest) \n",
    "\n",
    "        scaler = StandardScaler() \n",
    "        scaler.fit(Xtrain_im) \n",
    "        Xtrain_std = scaler.transform(Xtrain_im) \n",
    "        Xtest_std = scaler.transform(Xtest_im) \n",
    "\n",
    "        # Jij computed from training set Pearson correlations, diag set to 0 \n",
    "        rho = np.corrcoef(Xtrain_std, rowvar=False) \n",
    "        np.fill_diagonal(rho, 0.0) \n",
    "        Jij = rho.copy() \n",
    "\n",
    "        # Quantum features for all training and test samples \n",
    "        print(f\"Fold {fold_idx}: computing quantum features for {len(Xtrain_std)} train + {len(Xtest_std)} test samples...\") \n",
    "        #Xtilde_train = compute_quantum_features_aer_batch(Xtrain_std, Jij) \n",
    "        #Xtilde_test = compute_quantum_features_aer_batch(Xtest_std, Jij) \n",
    "        #Xtilde_train = compute_quantum_features_aer(Xtrain_std, Jij, shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL)\n",
    "        #Xtilde_test = compute_quantum_features_aer(Xtest_std, Jij, shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL)\n",
    "        Xtilde_train = run_quantum_feature_extraction(Xtrain_std, Jij, n_qubits=N_QUBITS,shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL)\n",
    "        Xtilde_test = run_quantum_feature_extraction(Xtest_std, Jij, n_qubits=N_QUBITS,shots=SHOTS, optimization_level=OPTIMIZATION_LEVEL)\n",
    "        \n",
    "        # Augment classical features with quantum features (gamma_q = 1) \n",
    "        Xaug_train = np.hstack([Xtrain_std, Xtilde_train]) \n",
    "        Xaug_test = np.hstack([Xtest_std, Xtilde_test]) \n",
    "        \n",
    "        # classifier \n",
    "        clf = GradientBoostingClassifier(random_state=RANDOM_STATE) \n",
    "        clf.fit(Xaug_train, ytrain) \n",
    "        ypred = clf.predict(Xaug_test) \n",
    "        yproba = clf.predict_proba(Xaug_test)[:, 1] \n",
    "        \n",
    "        # metrics \n",
    "        metrics['auc'].append(roc_auc_score(ytest, yproba)) \n",
    "        metrics['f1'].append(f1_score(ytest, ypred, zero_division=0)) \n",
    "        metrics['bal_acc'].append(balanced_accuracy_score(ytest, ypred)) \n",
    "        metrics['prec_0'].append(precision_score(ytest, ypred, pos_label=0, zero_division=0)) \n",
    "        metrics['rec_0'].append(recall_score(ytest, ypred, pos_label=0, zero_division=0)) \n",
    "        metrics['prec_1'].append(precision_score(ytest, ypred, pos_label=1, zero_division=0)) \n",
    "        metrics['rec_1'].append(recall_score(ytest, ypred, pos_label=1, zero_division=0)) \n",
    "\n",
    "    # Print median metrics (matching how the PDF aggregated by median across folds)\n",
    "    print(\"\\n=== Median metrics over 5 folds ===\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k:8s}: {np.median(v):.4f}\")\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "def _make_meta():\n",
    "    return {\n",
    "    \"REPS\": REPS,\n",
    "    \"M\": M,\n",
    "    \"ORDER\": ORDER,\n",
    "    \"DELTA_T\": DELTA_T,\n",
    "    \"A0\": A0,\n",
    "    \"B0\": B0,\n",
    "    \"TAU\": TAU,\n",
    "    \"RANDOM_STATE\": RANDOM_STATE\n",
    "    }\n",
    "\n",
    "def run_experiment_and_save(X, y, outdir=\"saved_models\", save_per_fold=True, save_final_model=True, aer_batch_kwargs=None):\n",
    "    if aer_batch_kwargs is None:\n",
    "        aer_batch_kwargs = {}\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    metrics = { 'auc': [], 'f1': [], 'bal_acc': [], 'prec_0': [], 'rec_0': [], 'prec_1': [], 'rec_1': [] }\n",
    "    artifact_paths = {\"folds\": {}, \"final\": {}}\n",
    "\n",
    "    fold_idx = 0\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        fold_idx += 1\n",
    "        Xtrain, Xtest = X[train_idx], X[test_idx]\n",
    "        ytrain, ytest = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Preprocessing fit on train only\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        imputer.fit(Xtrain)\n",
    "        Xtrain_im = imputer.transform(Xtrain)\n",
    "        Xtest_im = imputer.transform(Xtest)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(Xtrain_im)\n",
    "        Xtrain_std = scaler.transform(Xtrain_im)\n",
    "        Xtest_std = scaler.transform(Xtest_im)\n",
    "\n",
    "        # Jij from training set\n",
    "        rho = np.corrcoef(Xtrain_std, rowvar=False)\n",
    "        np.fill_diagonal(rho, 0.0)\n",
    "        Jij = rho.copy()\n",
    "\n",
    "        # Quantum features (uses compute_quantum_features_aer_batch)\n",
    "        print(f\"[Fold {fold_idx}] computing quantum features for {len(Xtrain_std)} train + {len(Xtest_std)} test samples...\")\n",
    "        Xtilde_train = compute_quantum_features_aer_batch(Xtrain_std, Jij, **aer_batch_kwargs)\n",
    "        Xtilde_test  = compute_quantum_features_aer_batch(Xtest_std,  Jij, **aer_batch_kwargs) \n",
    "\n",
    "        # Augment and train\n",
    "        Xaug_train = np.hstack([Xtrain_std, Xtilde_train])\n",
    "        Xaug_test  = np.hstack([Xtest_std,  Xtilde_test])\n",
    "\n",
    "        clf = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "        clf.fit(Xaug_train, ytrain)\n",
    "\n",
    "        ypred = clf.predict(Xaug_test)\n",
    "        # try to get probabilities; if unavailable, fill with None or zeros\n",
    "        try:\n",
    "            yproba = clf.predict_proba(Xaug_test)[:, 1]\n",
    "        except Exception:\n",
    "            yproba = None\n",
    "\n",
    "        # Collect metrics\n",
    "        # only compute AUC if probabilities are available\n",
    "        if yproba is not None:\n",
    "            metrics['auc'].append(roc_auc_score(ytest, yproba))\n",
    "        else:\n",
    "            metrics['auc'].append(np.nan)\n",
    "\n",
    "        metrics['f1'].append(f1_score(ytest, ypred, zero_division=0))\n",
    "        metrics['bal_acc'].append(balanced_accuracy_score(ytest, ypred))\n",
    "        metrics['prec_0'].append(precision_score(ytest, ypred, pos_label=0, zero_division=0))\n",
    "        metrics['rec_0'].append(recall_score(ytest, ypred, pos_label=0, zero_division=0))\n",
    "        metrics['prec_1'].append(precision_score(ytest, ypred, pos_label=1, zero_division=0))\n",
    "        metrics['rec_1'].append(recall_score(ytest, ypred, pos_label=1, zero_division=0))\n",
    "\n",
    "        # Save per-fold artifacts and per-fold metrics/predictions\n",
    "        fold_art = {}\n",
    "        if save_per_fold:\n",
    "            fold_dir = Path(outdir) / f\"fold_{fold_idx}\"\n",
    "            fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            model_path   = str(fold_dir / \"model.joblib\")\n",
    "            imputer_path = str(fold_dir / \"imputer.joblib\")\n",
    "            scaler_path  = str(fold_dir / \"scaler.joblib\")\n",
    "            Jij_path     = str(fold_dir / \"Jij.npy\")\n",
    "            meta_path    = str(fold_dir / \"meta.json\")\n",
    "            metrics_path = str(fold_dir / \"metrics.json\")\n",
    "            preds_path   = str(fold_dir / \"predictions.npz\")\n",
    "\n",
    "            joblib.dump(clf, model_path)\n",
    "            joblib.dump(imputer, imputer_path)\n",
    "            joblib.dump(scaler, scaler_path)\n",
    "            np.save(Jij_path, Jij)\n",
    "            with open(meta_path, \"w\") as fh:\n",
    "                json.dump(_make_meta(), fh, indent=2)\n",
    "\n",
    "            # per-fold metrics dictionary (turn NaN into null in JSON)\n",
    "            fold_metrics = {\n",
    "                \"auc\": (float(metrics['auc'][-1]) if not np.isnan(metrics['auc'][-1]) else None),\n",
    "                \"f1\": float(metrics['f1'][-1]),\n",
    "                \"bal_acc\": float(metrics['bal_acc'][-1]),\n",
    "                \"prec_0\": float(metrics['prec_0'][-1]),\n",
    "                \"rec_0\": float(metrics['rec_0'][-1]),\n",
    "                \"prec_1\": float(metrics['prec_1'][-1]),\n",
    "                \"rec_1\": float(metrics['rec_1'][-1]),\n",
    "                \"n_train\": int(len(Xtrain)),\n",
    "                \"n_test\": int(len(Xtest))\n",
    "            }\n",
    "            # save fold metrics JSON\n",
    "            with open(metrics_path, \"w\") as fh:\n",
    "                json.dump(fold_metrics, fh, indent=2)\n",
    "\n",
    "            # save predictions & test indices for reproducibility\n",
    "            # yproba may be None; if so store an array of NaNs\n",
    "            if yproba is None:\n",
    "                yproba_arr = np.full_like(ypred, np.nan, dtype=float)\n",
    "            else:\n",
    "                yproba_arr = np.asarray(yproba, dtype=float)\n",
    "\n",
    "            np.savez_compressed(preds_path,\n",
    "                                y_test=np.asarray(ytest),\n",
    "                                y_pred=np.asarray(ypred),\n",
    "                                y_proba=yproba_arr,\n",
    "                                test_indices=np.asarray(test_idx))\n",
    "\n",
    "            fold_art = {\n",
    "                \"model\": model_path,\n",
    "                \"imputer\": imputer_path,\n",
    "                \"scaler\": scaler_path,\n",
    "                \"Jij\": Jij_path,\n",
    "                \"meta\": meta_path,\n",
    "                \"metrics\": metrics_path,\n",
    "                \"predictions\": preds_path\n",
    "            }\n",
    "            artifact_paths[\"folds\"][fold_idx] = fold_art\n",
    "            print(f\"[Fold {fold_idx}] saved artifacts & metrics to {fold_dir}\")\n",
    "\n",
    "    # Aggregate & save metrics (medians as in the PDF)\n",
    "    metrics_median = {k: float(np.nanmedian(v)) for k, v in metrics.items()}\n",
    "    metrics_out = {\"per_fold\": metrics, \"median\": metrics_median}\n",
    "    metrics_path_all = str(Path(outdir) / \"metrics.json\")\n",
    "    with open(metrics_path_all, \"w\") as fh:\n",
    "        json.dump(metrics_out, fh, indent=2)\n",
    "    artifact_paths[\"metrics\"] = metrics_path_all\n",
    "\n",
    "    print(\"\\n=== Median metrics over 5 folds ===\")\n",
    "    for k, v in metrics_median.items():\n",
    "        print(f\"{k:8s}: {v:.4f}\")\n",
    "\n",
    "    # Train & save final model on full dataset if requested\n",
    "    if save_final_model:\n",
    "        print(\"Training final model on full dataset (will compute Jij from full data)...\")\n",
    "        # Preprocessing on full data\n",
    "        imputer_full = SimpleImputer(strategy='median')\n",
    "        imputer_full.fit(X)\n",
    "        X_im_full = imputer_full.transform(X)\n",
    "\n",
    "        scaler_full = StandardScaler()\n",
    "        scaler_full.fit(X_im_full)\n",
    "        X_std_full = scaler_full.transform(X_im_full)\n",
    "\n",
    "        Jij_full = np.corrcoef(X_std_full, rowvar=False)\n",
    "        np.fill_diagonal(Jij_full, 0.0)\n",
    "\n",
    "        # quantum features for full dataset (may be slow)\n",
    "        Xtilde_full = compute_quantum_features_aer_batch(X_std_full, Jij_full, **aer_batch_kwargs)\n",
    "\n",
    "        Xaug_full = np.hstack([X_std_full, Xtilde_full])\n",
    "\n",
    "        final_clf = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "        final_clf.fit(Xaug_full, y)\n",
    "\n",
    "        # Save final artifacts\n",
    "        final_dir = Path(outdir) / \"final\"\n",
    "        final_dir.mkdir(parents=True, exist_ok=True)\n",
    "        final_model_path = str(final_dir / \"final_model.joblib\")\n",
    "        imputer_full_path = str(final_dir / \"imputer_full.joblib\")\n",
    "        scaler_full_path = str(final_dir / \"scaler_full.joblib\")\n",
    "        Jij_full_path = str(final_dir / \"Jij_full.npy\")\n",
    "        meta_full_path = str(final_dir / \"meta_full.json\")\n",
    "\n",
    "        joblib.dump(final_clf, final_model_path)\n",
    "        joblib.dump(imputer_full, imputer_full_path)\n",
    "        joblib.dump(scaler_full, scaler_full_path)\n",
    "        np.save(Jij_full_path, Jij_full)\n",
    "        with open(meta_full_path, \"w\") as fh:\n",
    "            json.dump(_make_meta(), fh, indent=2)\n",
    "\n",
    "        artifact_paths[\"final\"] = {\n",
    "            \"model\": final_model_path,\n",
    "            \"imputer\": imputer_full_path,\n",
    "            \"scaler\": scaler_full_path,\n",
    "            \"Jij\": Jij_full_path,\n",
    "            \"meta\": meta_full_path\n",
    "        }\n",
    "        print(f\"Saved final model+artifacts to {final_dir}\")\n",
    "\n",
    "    return {\"metrics\": metrics_out, \"artifact_paths\": artifact_paths}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc33a6",
   "metadata": {},
   "source": [
    "Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041a146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: X=(171, 13), y=(171,), positive fraction=0.673\n",
      "Fold 1: computing quantum features for 136 train + 35 test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aer features:   1%|          | 1/136 [00:24<54:31, 24.23s/sample]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # load\n",
    "    df = load_dataset(dataset_save)\n",
    "\n",
    "    # PDF mapped NonToxic -> 1, Toxic -> 0\n",
    "    if 'Class' in df.columns or 'class' in df.columns:\n",
    "        name = 'Class' if 'Class' in df.columns else 'class'\n",
    "        y_raw = df[name].values\n",
    "        X = df.drop(columns=[name]).values\n",
    "\n",
    "\n",
    "    # Map textual labels to binary per PDF: NonToxic -> 1, Toxic -> 0\n",
    "    # If labels are already numeric {0,1}, keep them\n",
    "    if y_raw.dtype.kind in 'OU':  # object / strings\n",
    "        y = np.array([1 if str(v).lower().startswith('non') else 0 for v in y_raw], dtype=int)\n",
    "    else:\n",
    "        y = np.array(y_raw, dtype=int)\n",
    "\n",
    "    print(f\"Dataset shape: X={X.shape}, y={y.shape}, positive fraction={y.mean():.3f}\")\n",
    "\n",
    "    # Run experiment\n",
    "    metrics = run_experiment(X,y)\n",
    "    #metrics = run_experiment_and_save(X, y, outdir=\"saved_models_32_32\", save_per_fold=True, save_final_model=True, aer_batch_kwargs={\"batch_size\": 16, \"shots\": 1024, \"optimization_level\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ae572",
   "metadata": {},
   "source": [
    "Predict with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a605952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and preprocessing artifacts from saved_models_4_4\\final\n",
      "Quantum circuit params: {'REPS': 4, 'M': 4, 'ORDER': 2, 'DELTA_T': 7.5e-09, 'A0': 94247779607.69379, 'B0': 69115038378.97545, 'TAU': 3e-08, 'RANDOM_STATE': 42}\n",
      "Computing quantum features for 5 new samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aer batch features:   0%|          | 0/5 [00:00<?, ?sample/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aer batch features: 100%|██████████| 5/5 [00:01<00:00,  4.53sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 1 1 1 1]\n",
      "Predicted probabilities: [0.98395874 0.95508129 0.99005912 0.97341944 0.98635758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_with_saved_model(X_new, model_dir=\"saved_models/final\", aer_batch_kwargs=None):\n",
    "\n",
    "    if aer_batch_kwargs is None:\n",
    "        aer_batch_kwargs = {}\n",
    "\n",
    "    model_dir = Path(model_dir)\n",
    "    model_path = model_dir / \"final_model.joblib\"\n",
    "    imputer_path = model_dir / \"imputer_full.joblib\"\n",
    "    scaler_path  = model_dir / \"scaler_full.joblib\"\n",
    "    Jij_path     = model_dir / \"Jij_full.npy\"\n",
    "    meta_path    = model_dir / \"meta_full.json\"\n",
    "\n",
    "    # --- Load all artifacts ---\n",
    "    clf = joblib.load(model_path)\n",
    "    imputer = joblib.load(imputer_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    Jij = np.load(Jij_path)\n",
    "    with open(meta_path, \"r\") as fh:\n",
    "        meta = json.load(fh)\n",
    "\n",
    "    print(\"Loaded model and preprocessing artifacts from\", model_dir)\n",
    "    print(\"Quantum circuit params:\", meta)\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "    X_im = imputer.transform(X_new)\n",
    "    X_std = scaler.transform(X_im)\n",
    "\n",
    "    # --- Quantum features ---\n",
    "    print(f\"Computing quantum features for {len(X_std)} new samples...\")\n",
    "    X_tilde = compute_quantum_features_aer_batch(X_std, Jij, **aer_batch_kwargs)\n",
    "\n",
    "    # --- Augment and predict ---\n",
    "    X_aug = np.hstack([X_std, X_tilde])\n",
    "    y_proba = clf.predict_proba(X_aug)[:, 1]\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    return {\"y_pred\": y_pred, \"y_proba\": y_proba, \"X_aug\": X_aug}\n",
    "\n",
    "\n",
    "# Suppose you have a few test samples (same number of features as training)\n",
    "X_new = X[:5]  # or load from another CSV\n",
    "\n",
    "# Predict using the saved final model\n",
    "result = predict_with_saved_model(X_new, model_dir=\"saved_models_4_4/final\", aer_batch_kwargs={'batch_size': 4})\n",
    "\n",
    "print(\"Predicted labels:\", result['y_pred'])\n",
    "print(\"Predicted probabilities:\", result['y_proba'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DT_venv)",
   "language": "python",
   "name": "dt_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
